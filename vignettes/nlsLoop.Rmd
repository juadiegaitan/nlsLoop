---
title: "nlsLoop"
author: "Daniel Padfield"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{nlsLoop}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

__nlsLoop__ is a simple R package that gives a more reproducible and reliable method for fitting individual non-linear regression fits over levels of a factor. This procedure is commonly done using __nlme::nlsList__, but this function only uses one set of parameter values. Consequently, some curves fail to converge on the correct parameter values simply because of the starting values being too far away from the starting values. __nlsLoop__ improves on __nlme::nlsList__ by allowing multiple starting values for each parameter, thereby exploring more parameter space when model fitting. The best model is chosen based on AIC score, ensuring that the same run of __nlsLoop__ will always give the same set of parameters, as long as the number of tries for each fit is large enough.

This document provides an introduction into this one key use of __nlsLoop__, and also demonstrates its potential for producing predictions around each fit and exploratory plotting.

## An example non-linear model fit

This vignette will use data from a dataset of thermal response curves for photosynthesis and respiration of the aquatic phytoplankton _Chlorella vulgaris_ (Padfield _et. al_ 2016). This data represents the rate of photosynthesis and respiration at different short-term, assay temperatures (16 ºC to 46 ºC) and was done in triplicate at 5 growth temperatures (20  ºC, 23 ºC, 27 ºC, 30 ºC and 33 ºC) after both 10 (acclimation) and 100 (adaptation) generations of growth.

This gives 60 curves in total. These responses generally follow a unimodal response and there are various models that have been used to fit to the data. A very recent overview of these can be found [here](http://onlinelibrary.wiley.com/doi/10.1002/ece3.3576/epdf) and the authors also released an R package which contains many of these [models](https://cran.r-project.org/package=temperatureresponse) (Low-Decarie _et al._ 2017).

I will demonstrate how the unimodal resposne can be fitted with the Sharpe-Schoolfield equation of the form:

$$log(rate) = lnc + E(\frac{1}{T_{c}} - \frac{1}{kT}) - ln(1 + e^{E_h(\frac{1}{kT_h} - \frac{1}{kT})})$$

Where $k$ is Boltzmann's constant $8.62e^{-5}$ and $T$ is temperature in Kelvin. A detailed explanation of the other parameters model can be found [here](http://onlinelibrary.wiley.com/doi/10.1111/ele.12545/epdf)(Padfield _et. al_ 2016). 

We begin with loading in the data, which comes with the package.

```{r load_in data, tidy=TRUE}
# load in package
library(nlsLoop)

# load in data
data('Chlorella_TRC')

# look at column names
names(Chlorella_TRC)
```

We then need to specify the non-linear model to fit to the data

```{r schoolfield_high, tidy = TRUE}
# define the Sharpe-Schoolfield equation
schoolfield_high <- function(lnc, E, Eh, Th, temp, Tc) {
  Tc <- 273.15 + Tc
  k <- 8.62e-5
  boltzmann.term <- lnc + log(exp(E/k*(1/Tc - 1/temp)))
  inactivation.term <- log(1/(1 + exp(Eh/k*(1/Th - 1/temp))))
  return(boltzmann.term + inactivation.term)
  }
```

We can then run __nlsLoop__, as long as we have a column in the dataframe that identifies each level of the factor. This column, __id_col__, can be either a __character__ or a __factor__. It is useful to include information about the data, possibly the treatments, separated by '_' in this column. The __id_col__  can link the fitted model objects to the raw data, so being able to split this column back up into treatment columns is often a great option.

When first running __nlsLoop__, it is advisable to run a single __nls__ fit on the whole dataset to give your start parameters some ball park boundaries. If you do not then you may suffer the same problems with __nlsLoop__ as are experienced with __nlsList__.

```{r nlsLoop, message=FALSE, warning=FALSE, results='hide'}
fits <- nlsLoop(ln.rate ~ schoolfield_high(lnc, E, Eh, Th, temp = K, Tc = 20),
                     data = Chlorella_TRC,
                     tries = 500,
                     id_col = 'curve_id',
                     param_bds = c(-10, 10, 0.1, 2, 0.5, 10, 285, 330),
                     r2 = 'Y',
                     supp_errors = 'Y',
                     AICc = 'Y',
                     na.action = na.omit,
                     lower = c(lnc = -10, E = 0, Eh = 0, Th = 0))
```

The documentation for __nlsLoop__ can be found by using `?nlsLoop`. The argument `param_bds` sets upper and lower limits for each parameter from which random values between these are picked. The list of values goes through the lower and upper boundary for each parameter in turn (i.e. $lnc_{lower}$, $lnc_{lower}$, $E_{lower}$, $E_{upper}$ ...). A data frame is then created with `nrow = tries` of random draws of combinations from all of the parameter values. The model then loops through a call to __nlsLM__ for each of these sets of starting parameters. Each time the AIC score is lower for an individual fit (indicating a better relative fit), the parameter dataframe is updated.

When running through the iterations for each level of the factor, if the AIC score does not get lower, indicating a better relative fit, for 100 different calls of __nlsLM__ using different parameter values, __nlsLoop__ moves onto the next level of the factor.

__nlsLoop__ returns an `nlsLoop` object that works the same way as a list. It is made up of:
    - __formula__ the formula used in the fit
    - __info__ some information on the dependent and independent parameters. These are used in the plotting functions __plot_all_nlsLoop__ and __plot_id_nlsLoop__
    - __params__ which has all of our parameter values for each individual fit
    - __predictions__ which is a dataframe of the predicted fits of each curve, from each individual fits minimum and maximum predictor values. This is given in stacked, tidy format, ready for incorporation with ggplot2

```{r, look_at_fits}
# look at parameter values
head(fits$params)

# look at fits
head(fits$params)
```

Having all of the elements in a single __nlsLoop__ object allows a simple plotting method to assess how good our fits to the data are.  Although AIC scores pick the best model, this is relative to all the other fits and does not tell us anything about how well the model fits the data. The package does include a way to calculate a quasi-rsquared score, but use this at your own risk. Non-linear versions of rsquared do not necessarily mean the same thing as linear rsquared values do (Spiess & Neumeyer 2010). Another way of evaluating model fit is by plotting the predictions alongside the raw data.

__nlsLoop__ provides an easy wrapper to ggplot2 to do this. Firstly lets have a look at a single level of `curve_id`, a function called __plot_id_nlsLoop__ allows this.

```{r first_fit_plot, fig.height=5,  fig.width = 7}
plot_id_nlsLoop(data = Chlorella_TRC, param_data = fits, id = '1')
```

Further to this, __plot_all_nlsLoop__ will produce a pdf with each plot on a new sheet.

```{r pdf_fits, eval=FALSE}
plot_all_nlsLoop('path/of/where/you/want/to/save/me.pdf', data = Chlorella_TRC, param_data = fits)
```

Instead of using the plotting functions within the package, we can easily create plots using ggplot and the predictions dataframe. For example, we can plot all the curve fits split by growth temperature and acclimation _vs._ adaptation

```{r data_wrangling, fig.height=7,  fig.width = 7}
# get distinct values of process, flux and growth.temp for each value of curve_id
d_treatment <- Chlorella_TRC[,c('curve_id','process', 'growth.temp', 'flux')]
d_treatment <- d_treatment[!duplicated(d_treatment),]

# merge with predictions by curve_id
fits$predictions <- merge(fits$predictions, d_treatment, by = 'curve_id')

# plot every curve
library(ggplot2)
ggplot() +
  geom_point(aes(K - 273.15, ln.rate, col = flux), size = 2, Chlorella_TRC) +
  geom_line(aes(K - 273.15, ln.rate, col = flux, group = curve_id), alpha = 0.5, fits$predictions) +
  facet_wrap(~ growth.temp + process, labeller = labeller(.multi_line = F)) +
  scale_colour_manual(values = c('green4', 'black')) +
  theme_bw(base_size = 12, base_family = 'Helvetica') +
  ylab('log Metabolic rate') +
  xlab('Assay temperature (ºC)') +
  theme(legend.position = c(0.9, 0.15))

```

We can also start having a quick look at any differences between parameters. Here we will plot them pooled between fluxes.

```{r parameter_plots, fig.height=5, fig.width=6}
# merge params with d_treatment by curve_id
fits$params <- merge(fits$params, d_treatment, by = 'curve_id')

library(tidyr)

gather(fits$params, 'parameter', 'value', c(lnc, E, Eh, Th)) %>%
  ggplot(., aes(flux, value, col = flux)) +
  geom_boxplot(fill = 'white', outlier.shape = NA) +
  geom_point(position = position_jitter(height = 0, width = 0.1)) +
  facet_wrap(~ parameter, scales = 'free_y') +
  scale_color_manual(values = c('green4', 'black')) +
  scale_shape_manual(values = c(21, 24)) +
  theme_bw(base_size = 12, base_family = 'Helvetica') +
  theme(legend.position = 'top')
```

The confidence intervals of each fit can also be calculated using __confint_nlsLoop__.

```{r, confint_nlsLoop, fig.width = 7, fig.height = 8}
# calculate confidence intervals for each fit
CIs <- confint_nlsLoop(Chlorella_TRC, fits)

# bind with factors dataframe
CIs <- merge(CIs, d_treatment, by = 'curve_id')

# plot
ggplot(CIs, aes(col = flux)) +
  geom_point(aes(curve_id, mean)) +
  facet_wrap(~ param, scale = 'free_x', ncol = 4) +
  geom_linerange(aes(curve_id, ymin = CI_lwr, ymax = CI_upr)) +
  coord_flip() +
  scale_color_manual(values = c('green4', 'black')) +
  theme_bw(base_size = 12, base_family = 'Helvetica') +
  theme(legend.position = 'top') +
  xlab('curve') +
  ylab('parameter estimate')



```

When you are happy with your starting parameter values, __nlsLoop2__ can be used to speed up your model fitting by using __nls2__ to generate multiple starting values.



__nlsLoop__ provides a more reliable and reproducible way of getting individual non-linear fits over levels of a factor of a dataframe. I hope this vignette has provided a good overview of its benefits and usage.

### References:

- Low-Décarie, E., Boatman, T.G., Bennett, N., Passfield, W., Gavalás-Olea, A., Siegel, P. & Geider, R.J. (2017) Predictions of response to temperature are contingent on model choice and data quality. Ecology & Evolution.
- Padfield, D., Yvon-durocher, G., Buckling, A., Jennings, S. & Yvon-durocher, G. (2015). Rapid evolution of metabolic traits explains thermal adaptation in phytoplankton. Ecology Letters, 19(2), 133-142.
- Schoolfield, R.M., Sharpe, P.J. & Magnuson, C.E. (1981). Non-linear regression of biological temperature-dependent rate models based on absolute reaction-rate theory. J. Theoretical Biology, 88, 719–31.
